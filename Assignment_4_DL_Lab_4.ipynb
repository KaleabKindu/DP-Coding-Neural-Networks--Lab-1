{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaleabKindu/DP-Coding-Neural-Networks-Lab/blob/main/Assignment_4_DL_Lab_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E-apHeQahmI"
      },
      "source": [
        "### Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "nlf-0k4OaffJ"
      },
      "outputs": [],
      "source": [
        "class Activation_Sigmoid:\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    self.output = 1 / (1 + torch.exp(inputs*-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93Dox6rDcVvN"
      },
      "source": [
        "## Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "p5KqLXjIcYQK"
      },
      "outputs": [],
      "source": [
        "class Accuracy():\n",
        "  def calculate(self, y_pred, y_true):\n",
        "    predictions = torch.argmax(y_pred, axis=1)\n",
        "    if len(y_true.shape) == 2:\n",
        "      y_true = torch.argmax(y_true, axis=1)\n",
        "    accuracy = torch.mean((predictions == y_true).float())\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "class DenseLayer:\n",
        "  # Layer initialization\n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "    # Initialize weights and biases\n",
        "    self.weights = 0.01 * torch.rand(n_neurons, n_inputs)\n",
        "    self.biases = torch.zeros((1, n_neurons))\n",
        "    self.output = None\n",
        "\n",
        "  # Forward pass\n",
        "  def forward(self, inputs):\n",
        "    # Calculate output values from inputs, weights and biases\n",
        "    self.output = torch.matmul(inputs, self.weights.t()) + self.biases\n",
        "\n",
        "class RegressionModel:\n",
        "    def __init__(self, num_of_features, num_of_output):\n",
        "        # Creating the model\n",
        "        self.hidden_layer = DenseLayer(num_of_features, 4)\n",
        "        self.activation1 = Activation_Sigmoid()\n",
        "        self.output_layer = DenseLayer(4, num_of_output)\n",
        "\n",
        "        # Learning rate\n",
        "        self.learning_rate = 0.01\n",
        "\n",
        "    def forward_pass(self, X):\n",
        "        # Forward pass\n",
        "        self.hidden_layer.forward(X)\n",
        "        self.activation1.forward(self.hidden_layer.output)\n",
        "        self.output_layer.forward(self.activation1.output)\n",
        "        return self.output_layer.output\n",
        "\n",
        "    def loss_function(self, y_true, y_pred):\n",
        "      return torch.mean(0.5*(y_true - y_pred)**2)\n",
        "\n",
        "    def back_prop(self, y, fp):\n",
        "        dloss_doutput_1 = fp[0][0] - y[0][0]\n",
        "        dloss_doutput_2 = fp[0][1] - y[0][1]\n",
        "\n",
        "        self.output_layer.weights[0][0] -= self.learning_rate * dloss_doutput_1*self.activation1.output[0][0]\n",
        "        self.output_layer.weights[0][1] -= self.learning_rate * dloss_doutput_1*self.activation1.output[0][1]\n",
        "        self.output_layer.weights[0][2] -= self.learning_rate * dloss_doutput_1*self.activation1.output[0][2]\n",
        "        self.output_layer.weights[0][3] -= self.learning_rate * dloss_doutput_1*self.activation1.output[0][3]\n",
        "\n",
        "        self.output_layer.weights[0][0] -= self.learning_rate * dloss_doutput_2*self.activation1.output[0][0]\n",
        "        self.output_layer.weights[0][1] -= self.learning_rate * dloss_doutput_2*self.activation1.output[0][1]\n",
        "        self.output_layer.weights[0][2] -= self.learning_rate * dloss_doutput_2*self.activation1.output[0][2]\n",
        "        self.output_layer.weights[0][3] -= self.learning_rate * dloss_doutput_2*self.activation1.output[0][3]\n",
        "\n",
        "\n",
        "        self.output_layer.biases[0][0] -= self.learning_rate * dloss_doutput_1\n",
        "        self.output_layer.biases[0][1] -= self.learning_rate * dloss_doutput_2\n",
        "\n",
        "        activation_1 = self.activation1.output[0][0] * ( 1 - self.activation1.output[0][0])\n",
        "        activation_2 = self.activation1.output[0][1] * ( 1 - self.activation1.output[0][1])\n",
        "        activation_3 = self.activation1.output[0][2] * ( 1 - self.activation1.output[0][2])\n",
        "        activation_4 = self.activation1.output[0][3] * ( 1 - self.activation1.output[0][3])\n",
        "\n",
        "        self.hidden_layer.weights[0][0] -= self.learning_rate * ( ((dloss_doutput_1 * self.output_layer.weights[0][0]) + (dloss_doutput_2 * self.output_layer.weights[1][0])) * activation_1 * X[0][0])\n",
        "        self.hidden_layer.weights[0][1] -= self.learning_rate * ( (dloss_doutput_1 * self.output_layer.weights[0][0] + dloss_doutput_2 * self.output_layer.weights[1][0]) * activation_1 * X[0][1])\n",
        "\n",
        "        self.hidden_layer.weights[1][0] -= self.learning_rate * ( ((dloss_doutput_1 * self.output_layer.weights[0][1]) + (dloss_doutput_2 * self.output_layer.weights[1][1])) * activation_2 * X[0][0])\n",
        "        self.hidden_layer.weights[1][1] -= self.learning_rate * ( (dloss_doutput_1 * self.output_layer.weights[0][1] + dloss_doutput_2 * self.output_layer.weights[1][1]) * activation_2 * X[0][1])\n",
        "\n",
        "        self.hidden_layer.weights[2][0] -= self.learning_rate * ( ((dloss_doutput_1 * self.output_layer.weights[0][2]) + (dloss_doutput_2 * self.output_layer.weights[1][2])) * activation_3 * X[0][0])\n",
        "        self.hidden_layer.weights[2][1] -= self.learning_rate * ( (dloss_doutput_1 * self.output_layer.weights[0][2] + dloss_doutput_2 * self.output_layer.weights[1][2]) * activation_3 * X[0][1])\n",
        "\n",
        "        self.hidden_layer.weights[3][0] -= self.learning_rate * ( ((dloss_doutput_1 * self.output_layer.weights[0][3]) + (dloss_doutput_2 * self.output_layer.weights[1][3])) * activation_4 * X[0][0])\n",
        "        self.hidden_layer.weights[3][1] -= self.learning_rate * ( (dloss_doutput_1 * self.output_layer.weights[0][3] + dloss_doutput_2 * self.output_layer.weights[1][3]) * activation_4 * X[0][1])\n",
        "\n",
        "\n",
        "    def train(self, X, y, epochs=1000):\n",
        "        for epoch in range(epochs):\n",
        "            y_pred = self.forward_pass(X)\n",
        "            self.back_prop(y, y_pred)\n",
        "\n",
        "            if epoch % 100 == 0:\n",
        "                loss = self.loss_function(y_pred, y)\n",
        "                print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
        "\n",
        "        print(\"Final prediction:\", y_pred)\n",
        "        print(\"Target value:\", y)\n",
        "\n",
        "# Example usage:\n",
        "num_of_features = 2\n",
        "num_of_output = 2\n",
        "\n",
        "# Create model\n",
        "model = RegressionModel(num_of_features, num_of_output)\n",
        "\n",
        "# Dummy input and target values\n",
        "X = torch.tensor([[0.2, 0.7]])\n",
        "y = torch.tensor([[0.4, 0.8]])\n",
        "\n",
        "# Train the model\n",
        "model.train(X, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeXKTCmq1G6J",
        "outputId": "9251e8cd-bef9-42cc-8285-20300cafe005"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.1939796805381775\n",
            "Epoch 100, Loss: 0.025125527754426003\n",
            "Epoch 200, Loss: 0.004562072455883026\n",
            "Epoch 300, Loss: 0.0006893342942930758\n",
            "Epoch 400, Loss: 9.648445848142728e-05\n",
            "Epoch 500, Loss: 1.3135511835571378e-05\n",
            "Epoch 600, Loss: 1.7705583559290972e-06\n",
            "Epoch 700, Loss: 2.378324666096887e-07\n",
            "Epoch 800, Loss: 3.191319564166406e-08\n",
            "Epoch 900, Loss: 4.271980102998896e-09\n",
            "Final prediction: tensor([[0.4000, 0.8000]])\n",
            "Target value: tensor([[0.4000, 0.8000]])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}